{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9639b747",
   "metadata": {},
   "source": [
    "**MODEL OPTIMIZATION*\n",
    "\n",
    "1. In the baseline model I only used CountVectorizer. In this model I will use TF-IDF for model to learn word weights better\n",
    "2. I will also optimise some hyperparameters such as \"max_features\" and \"ngram_range\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a9a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca1e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src import config\n",
    "RAW_DATA_PATH = config.RAW_DATA_PATH\n",
    "PROCESSED_DATA_PATH = config.PROCESSED_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9c86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PROCESSED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e2ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].fillna('')\n",
    "df['tags'] = df['tags'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426d8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined_text\"] = df[\"description\"] + \" \" + df[\"tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc77e63",
   "metadata": {},
   "source": [
    "**TRYING DIFFERENT 'max_features' VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10587dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_try = [1000, 5000, 10000]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4661203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee208ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max features: 1000 in progress...\n",
      "Completed. Time: 1.78 sec\n",
      "Max features: 5000 in progress...\n",
      "Completed. Time: 1.82 sec\n",
      "Max features: 10000 in progress...\n",
      "Completed. Time: 1.75 sec\n"
     ]
    }
   ],
   "source": [
    "for n_features in features_to_try:\n",
    "    print(f\"Max features: {n_features} in progress...\")\n",
    "    star_time = time.time()\n",
    "\n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\", max_features=n_features)\n",
    "    tfidf_matrix = tfidf.fit_transform(df[\"combined_text\"])\n",
    "\n",
    "    cosine_sim = linear_kernel(tfidf_matrix[test_idx:test_idx+1], tfidf_matrix)\n",
    "\n",
    "    elapsed = time.time() - star_time\n",
    "    results.append({\"features\": n_features,\n",
    "                    \"time\": elapsed})\n",
    "    \n",
    "    print(f\"Completed. Time: {elapsed:.2f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223439da",
   "metadata": {},
   "source": [
    "Increasing max_features from 1,000 to 10,000 did not significantly change the processing time, which stayed around 1.7â€“1.8 seconds. This shows that the vectorizer scales efficiently, and larger vocabularies do not add noticeable overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768cddba",
   "metadata": {},
   "source": [
    "**N-GRAM RANGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15723400",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bigram = TfidfVectorizer(stop_words=\"english\", max_features=10000, ngram_range=(1, 2))\n",
    "tfidf_matrix_bigram = tfidf_bigram.fit_transform(df[\"combined_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d515dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram matris shape: (70948, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bigram matris shape:\", tfidf_matrix_bigram.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
